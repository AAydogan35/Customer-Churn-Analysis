{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_telecom_01.csv',delimiter =',') #data added in repo\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset shape: ', df.shape)\n",
    "print('\\n')\n",
    "df.rename(columns={'service_06': 'Service_06'}, inplace=True)\n",
    "\n",
    "#removing user id from dataset\n",
    "df.drop('uid', axis = 1, inplace = True)\n",
    "\n",
    "df[['Factor_00','is_churn']] = df[['Factor_00','is_churn']].astype('category')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing values. Charges Column has 11 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_data = df.isnull()\n",
    "\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print(missing_data[column].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing value is %0.15 of the column. Thus, they will be filled with the mean value of the \"Charges\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_charges = df[\"Charges\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Avg of Charges: \", avg_charges, \"\\n\")\n",
    "\n",
    "df[\"Charges\"].replace(np.nan, avg_charges, inplace = True)\n",
    "\n",
    "missing_data = df.isnull()\n",
    "print(missing_data[\"Charges\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is biased in terms of the target variable. A dataset with equal number of instances will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with \"Class Imbalance\" problem. Creating same size target variable set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df[df['is_churn']=='Yes']\n",
    "print(\"Churned-data1:\"+ str(data1.shape))\n",
    "data2 = df[df['is_churn']=='No']\n",
    "print(\"Non Churn-data2:\"+ str(data2.shape))\n",
    "print(\"\")\n",
    "print(\"As we see %74 of the data set is Non churners. Therefore, if we estimate all as 0 we'd achieve %74 accuracy. \\n \")\n",
    "\n",
    "# Sample Non Churners class\n",
    "data2 = resample(data2, \n",
    "                replace=True,     # sample with replacement\n",
    "                n_samples=1869,    # to match Churners class\n",
    "                random_state=237) # reproducible results 123\n",
    "\n",
    "#Want same sized data on both classes\n",
    "df = data1.append(data2[:1869])\n",
    "print(\"Final Dataset :\"+ str(df.shape))\n",
    "df['is_churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the Gender, Factors and Service info play important role in whether a customer will churn.\n",
    "\n",
    "Some of the insights from the code below;\n",
    "\n",
    "- Gender does not play distinctive role in churn.\n",
    "\n",
    "- When Factor 1 is \"No\" it seems more likely to a customer to churn.\n",
    "- When Factor 2 is \"Yes\" it seems more likely for a customer to churn.\n",
    "\n",
    "- Service 1 doesn't tell much\n",
    "- Service 2: Categories doesn't tell much (0,33 - 0,33 - 0,40) but service 2 and 1's Yes and No are same numbers. Service 2   has additional \"No phone service\" info\n",
    "- Service 3: Fiber Optic customers are more likely to churn than DSL and \"No\" customers.\n",
    "- Service 4: \"No\" customers are more likley to churn than \"No internet service\" and \"Yes\" customers.\n",
    "- Service 5: \"No\" customers are more likely to churn than \"No internet service\" and \"Yes\" customers.\n",
    "- Service 6: \"No\" customers are more likely to churn than \"No internet service\" and \"Yes\" customers.\n",
    "- Service 7: \"No\" customers are more likely to chrun than \"No internet service\" and \"Yes\" customers.\n",
    "- Service 8: \"No\" and \"Yes\" customers are more likely to churn than \"No internet service\" customers.\n",
    "- Service 9: \"No\" and \"Yes\" customers are more likely to churn than \"No internet service\" customers.\n",
    "\n",
    "- C 1: \"Month-to-month\" customers seems more likely to churn than \"One Year\" and \"Two Year\" customers.\n",
    "- C 2: \"Yes\" customers are more likely to churn than \"No\" customers.\n",
    "- C 3: \"Electronic Check\" customers are more likely to churn than orher \"Bank Transfer (automatic)\", \"Credit Card             (automatic)\", \"Mailed Check\" customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    print(df.groupby(column)['is_churn'].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Churners pay less then non-churners. Reason could be service quality related, Factor_00 or Factor_03 can be indicator in churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\" --- Means\"+\" \"+\"---\"*7)\n",
    "print(df.groupby(['is_churn']).mean())\n",
    "print(\"\\n --- Std Deviations\"+\" \"+\"---\"*7)\n",
    "print(df.groupby(['is_churn']).std())\n",
    "print(\"\\n --- Counts\"+\" \"+\"---\"*7)\n",
    "print(df.groupby(['is_churn']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Legend: Churn\n",
    "- Monthly Charges - Factor 3 comparison: Customers that churn accumulates on higher Monthly Charges\n",
    "- Charges - Factor 3 comparison: Positive correlation observed on both churned (Stronger) and non churn customers. Charges effects more than Factor 3. As Factor 3 increases, Charges increase yet churned customers accumulates on increasing charges.\n",
    "- As Charges increase Monthly Charges increase. Churned customers accumulates more on higher Monthly Charges than Charges. This can be extra spendings on regular tariff.\n",
    "\n",
    "Legend: Service 3\n",
    "- Expensive to cheap: Fiber Optic - DSL - No. Fiber Optic is the most expensive factor and this can be one reason for it is to be the most churnes come from in its category.\n",
    "\n",
    "Legend: Service 4-5-6-7-8-9\n",
    "- These (Service 4-5-6-7) customers (\"No\") are all over the place yet they churn more than the others. This can be due to paying same money but not getting related additional services.\n",
    "- These (8-9) customers (Yes) churn more than other customers that use services. Unlike other services, this can be due to service quality.\n",
    "\n",
    "Legend: C01 - C02 - C03\n",
    "- C01: \"Month to Month\" customers were churning more, as they appear to accumulate more on higher Monthly Charges.\n",
    "- C02: \"Yes\" customers were churning more than No customers. This can be due to that they accumulate more on higher Monthly Charges\n",
    "- C03: Partially same applies to Electronic Check Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "g = sns.pairplot(df,\n",
    "                 x_vars=[\"MonthlyCharges\", \"Charges\", \"Factor_03\"], \n",
    "                 y_vars=[\"Factor_03\", \"MonthlyCharges\", \"Charges\"], \n",
    "                 hue = 'is_churn', \n",
    "                 markers=[\"X\", \"s\"], height = 4)\n",
    "g.fig.suptitle(\"Data Correlations\", y = 1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking correlations between numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix\n",
    "corr = df1.corr() #df\n",
    "#print(corr)\n",
    "# Generating a heatmap\n",
    "fig, ax = plt.subplots(figsize=(20,20))         # Sample figsize in inches\n",
    "\n",
    "sns.heatmap(corr,xticklabels=corr.columns, yticklabels=corr.columns,\n",
    "            annot=True, linewidths=.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df1, \n",
    "              x_vars = [\"C_01\",\"C_02\",\"C_03\"],\n",
    "              y_vars = [\"C_01\",\"C_02\",\"C_03\"],\n",
    "             height = 5,\n",
    "             hue = 'is_churn'\n",
    "             )\n",
    "plt.show() #,\"Service_06\",\"Service_07\",\"Service_08\",\"Service_09\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below; \n",
    "- Graph 1 shows that Factor 3 can be used in predicting the churn as churned customers have lower factor values. Altough the gender info does not play inportant role. Variables like, Service 2-3 etc plays role.\n",
    "- 2ns graph shows Monthly Charges can also be distinctive to some point on churn\n",
    "- 3th graph shows Charges are also helpful to some point understanding the churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'is_churn', y = 'Factor_03', data = df, hue = 'Service_08').set_title('1st') #sym = \"\", hue = 'gend' \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('is_churn','MonthlyCharges', data = df, hue = 'Factor_00').set_title('2nd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('is_churn','Charges', data = df, hue = 'Service_09').set_title('3th')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of the numeric variables\n",
    "\n",
    "Looking for normal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MonthlyCharges'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Charges'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Factor_03'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Feature Engineering / Encoding Binary Features & One Hot Encoding\n",
    "- Unable to perform feature engineering since no domain knowledge is provided and features are anonym\n",
    "- Features like Gender can be discarded from future model to be tried\n",
    "- Mean encoding is used as an encoding method. Also, one hot encoding could be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing: yes, no mapping for target column\n",
    "df[['Factor_00','is_churn']] = df[['Factor_00','is_churn']].astype('object')\n",
    "\n",
    "df['is_churn'].replace([\"Yes\",\"No\"],[1,0], regex = True, inplace = True)\n",
    "\n",
    "df['is_churn'] = df['is_churn'].astype('int')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Encoding for the Feature Variables\n",
    "\n",
    "General formula: \n",
    "Encoding for Gender = \n",
    "[Number of true (1) targets under the label Male / Total Number of targets under the label Male]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new df object\n",
    "df1 = df.copy(deep=True)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing feature classes with Target Means\n",
    "\n",
    "for column in df1:\n",
    "    \n",
    "    if df1[column].dtype == (object or category):\n",
    "        means = df1.groupby(column)['is_churn'].mean()\n",
    "        df1[column] = df1[column].map(means)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Encoding applied for the categorigal features. For the numeric variables, Normalization will be applied with Min - Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Factor_03'] = (df1['Factor_03'] - df1['Factor_03'].min())/(df1['Factor_03'].max()-df1['Factor_03'].min())\n",
    "df1['MonthlyCharges'] = (df1['MonthlyCharges'] - df1['MonthlyCharges'].min())/(df1['MonthlyCharges'].max()-df1['MonthlyCharges'].min())\n",
    "df1['Charges'] = (df1['Charges'] - df1['Charges'].min())/(df1['Charges'].max()-df1['Charges'].min())\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for model development and classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Model Development\n",
    "- ### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X = df1.copy(deep=True)\n",
    "y = X['is_churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) \n",
    "\n",
    "#Train Model\n",
    "svmodel = SVC(kernel='poly', degree = 5, gamma = 'auto')\n",
    "svmodel.fit(X_train, y_train)\n",
    "\n",
    "#Make prediction\n",
    "y_pred = svmodel.predict(X_test)\n",
    "\n",
    "#Model evaluation (Conf. mat, precision and F1 scores)\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#heatmap visualization\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt ='d',cbar=False,\n",
    "           xticklabels=True,yticklabels=True)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "print(classification_report(y_test,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model accuracy with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(svmodel, X, y, cv=10)\n",
    "np.average(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):  \n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "plot_roc_curve(fpr, tpr)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "- List of different penalty parameter 'C' are used for svm model.\n",
    "    - [0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "accuracy_list = []\n",
    "\n",
    "for c in C_list:\n",
    "    #Train Model\n",
    "    svmodel = SVC(kernel='poly', degree = 5, gamma = 'auto', C = c)\n",
    "    svmodel.fit(X_train, y_train)\n",
    "    #Make prediction\n",
    "    y_pred = svmodel.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    accuracy_list.append(auc)\n",
    "\n",
    "sns.barplot(y=accuracy_list, x=[0.001, 0.01, 0.1, 1, 10, 100, 1000], palette=\"Blues_d\")\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xlabel('C Parameter')\n",
    "plt.title('C Parameter AUC Scores')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion matrix and Precision-Recall scores of C = 1000 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "svmodel = SVC(kernel='poly', degree = 5, gamma = 'auto', C = 1000)\n",
    "svmodel.fit(X_train, y_train)\n",
    "\n",
    "#Make prediction\n",
    "y_pred = svmodel.predict(X_test)\n",
    "\n",
    "#Model evaluation (Conf. mat, precision and F1 scores)\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#heatmap visualization\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt ='d',cbar=False,\n",
    "           xticklabels=True,yticklabels=True)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "print(classification_report(y_test,y_pred),\"\\n\")\n",
    "print(\"Class Counts:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "#Fitting model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predicting Class\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "#Model evaluation (Conf. mat, precision and F1 scores)\n",
    "mat1 = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "#heatmap visualization\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt ='d',cbar=False,\n",
    "           xticklabels=True,yticklabels=True)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "print(classification_report(y_test,y_predict),\"\\n\")\n",
    "print(\"Class Counts:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_predict)\n",
    "print('ROC AUC: %f' % auc)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n",
    "plot_roc_curve(fpr, tpr)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
